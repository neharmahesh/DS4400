{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e1f0c33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 19)\n",
      "Testing data shape: (1000, 21)\n",
      "\n",
      "Training columns: ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
      "Testing columns: ['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('train.csv', index_col=0)\n",
    "test_data = pd.read_csv('test.csv', index_col=0)\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Testing data shape: {test_data.shape}\")\n",
    "\n",
    "# Show columns\n",
    "print(f\"\\nTraining columns: {list(train_data.columns)}\")\n",
    "print(f\"Testing columns: {list(test_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1cd694f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data separated successfully\n",
      "Training features shape: (1000, 17)\n",
      "Testing features shape: (1000, 17)\n",
      "\n",
      "Features used (17 total):\n",
      "['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X_train = train_data.drop(columns=['zipcode', 'price'])\n",
    "y_train = train_data['price'] / 1000\n",
    "  \n",
    "cols_to_drop_test = ['zipcode', 'price']\n",
    "if 'id' in test_data.columns:\n",
    "    cols_to_drop_test.append('id')\n",
    "if 'date' in test_data.columns:\n",
    "    cols_to_drop_test.append('date')\n",
    "\n",
    "X_test = test_data.drop(columns=cols_to_drop_test)\n",
    "y_test = test_data['price'] / 1000\n",
    "\n",
    "print(f\"\\nData separated successfully\")\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "print(f\"\\nFeatures used ({X_train.shape[1]} total):\")\n",
    "print(list(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa13e0-85e5-438d-819a-4c1e6004948c",
   "metadata": {},
   "source": [
    "# Problem 2:  Linear regression (15 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f54c1be-d53c-4b46-978c-7717b61bf4e1",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "077f415c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features standardized (mean ≈ 0, std ≈ 1)\n",
      "  Verification: mean = -0.000000, std = 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Formats\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "X_train_np = X_train_scaled\n",
    "y_train_np = y_train.values\n",
    "X_test_np = X_test_scaled  \n",
    "y_test_np = y_test.values\n",
    "\n",
    "print(\"Features standardized (mean ≈ 0, std ≈ 1)\")\n",
    "print(f\"  Verification: mean = {X_train_scaled.mean():.6f}, std = {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ff6b1fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained\n"
     ]
    }
   ],
   "source": [
    "# Train the linear regression model\n",
    "model_sklearn = LinearRegression()\n",
    "model_sklearn.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c98d948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LINEAR REGRESSION COEFFICIENTS\n",
      "================================================================================\n",
      "\n",
      "Intercept (θ₀): 520.414834\n",
      "\n",
      "Feature Coefficients:\n",
      "--------------------------------------------------------------------------------\n",
      "  bedrooms            : -12.521962\n",
      "  bathrooms           :  18.527633\n",
      "  sqft_living         :  56.748837\n",
      "  sqft_lot            :  10.881868\n",
      "  floors              :   8.043721\n",
      "  waterfront          :  63.742900\n",
      "  view                :  48.200109\n",
      "  condition           :  12.964269\n",
      "  grade               :  92.231475\n",
      "  sqft_above          :  48.290089\n",
      "  sqft_basement       :  27.137032\n",
      "  yr_built            : -67.643117\n",
      "  yr_renovated        :  17.271380\n",
      "  lat                 :  78.375737\n",
      "  long                :  -1.035203\n",
      "  sqft_living15       :  45.577658\n",
      "  sqft_lot15          : -12.930091\n"
     ]
    }
   ],
   "source": [
    "# Display all coefficients\n",
    "print(\"=\"*80)\n",
    "print(\"LINEAR REGRESSION COEFFICIENTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nIntercept (θ₀): {model_sklearn.intercept_:.6f}\\n\")\n",
    "print(\"Feature Coefficients:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for feature, coef in zip(X_train.columns, model_sklearn.coef_):\n",
    "    print(f\"  {feature:20s}: {coef:10.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1c8bcc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING SET METRICS\n",
      "================================================================================\n",
      "MSE:  31486.167776\n",
      "R²:   0.726533\n",
      "RMSE: 177.443421\n"
     ]
    }
   ],
   "source": [
    "# Calculate training metrics\n",
    "y_train_pred_sklearn = model_sklearn.predict(X_train_scaled_df)\n",
    "train_mse_sklearn = mean_squared_error(y_train, y_train_pred_sklearn)\n",
    "train_r2_sklearn = r2_score(y_train, y_train_pred_sklearn)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING SET METRICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"MSE:  {train_mse_sklearn:.6f}\")\n",
    "print(f\"R²:   {train_r2_sklearn:.6f}\")\n",
    "print(f\"RMSE: {np.sqrt(train_mse_sklearn):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08d6ed",
   "metadata": {},
   "source": [
    "## Part 2: Evaluate on Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec57066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING SET METRICS\n",
      "================================================================================\n",
      "MSE:  57628.154706\n",
      "R²:   0.654356\n",
      "RMSE: 240.058648\n"
     ]
    }
   ],
   "source": [
    "# Calculate testing metrics\n",
    "y_test_pred_sklearn = model_sklearn.predict(X_test_scaled_df)\n",
    "test_mse_sklearn = mean_squared_error(y_test, y_test_pred_sklearn)\n",
    "test_r2_sklearn = r2_score(y_test, y_test_pred_sklearn)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TESTING SET METRICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"MSE:  {test_mse_sklearn:.6f}\")\n",
    "print(f\"R²:   {test_r2_sklearn:.6f}\")\n",
    "print(f\"RMSE: {np.sqrt(test_mse_sklearn):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de5a0b",
   "metadata": {},
   "source": [
    "## Part 3: Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5afe9a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURES RANKED BY IMPORTANCE\n",
      "================================================================================\n",
      "      Feature  Coefficient  Abs_Coefficient\n",
      "        grade    92.231475        92.231475\n",
      "          lat    78.375737        78.375737\n",
      "     yr_built   -67.643117        67.643117\n",
      "   waterfront    63.742900        63.742900\n",
      "  sqft_living    56.748837        56.748837\n",
      "   sqft_above    48.290089        48.290089\n",
      "         view    48.200109        48.200109\n",
      "sqft_living15    45.577658        45.577658\n",
      "sqft_basement    27.137032        27.137032\n",
      "    bathrooms    18.527633        18.527633\n",
      " yr_renovated    17.271380        17.271380\n",
      "    condition    12.964269        12.964269\n",
      "   sqft_lot15   -12.930091        12.930091\n",
      "     bedrooms   -12.521962        12.521962\n",
      "     sqft_lot    10.881868        10.881868\n",
      "       floors     8.043721         8.043721\n",
      "         long    -1.035203         1.035203\n"
     ]
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': model_sklearn.coef_,\n",
    "    'Abs_Coefficient': np.abs(model_sklearn.coef_)\n",
    "})\n",
    "coef_df = coef_df.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURES RANKED BY IMPORTANCE\")\n",
    "print(\"=\"*80)\n",
    "print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d51e1089",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INTERPRETATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "1. TOP 3 CONTRIBUTING FEATURES:\n",
      "   - grade: 92.2315\n",
      "     → 1 std increase increases price by $92.23k\n",
      "   - lat: 78.3757\n",
      "     → 1 std increase increases price by $78.38k\n",
      "   - yr_built: -67.6431\n",
      "     → 1 std increase decreases price by $67.64k\n",
      "\n",
      "2. MODEL FIT QUALITY:\n",
      "   - Training R² = 0.7265 (72.7% variance explained)\n",
      "   - Testing R²  = 0.6544 (65.4% variance explained)\n",
      "\n",
      "3. PREDICTION ERROR:\n",
      "   - Testing RMSE = $240.06k\n",
      "   - In dollars: ±$240059\n",
      "\n",
      "4. GENERALIZATION:\n",
      "   - Test/Train MSE ratio = 1.8303\n",
      "   - Poor generalization (significant overfitting)\n"
     ]
    }
   ],
   "source": [
    "# Interpretation summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. TOP 3 CONTRIBUTING FEATURES:\")\n",
    "for idx, row in coef_df.head(3).iterrows():\n",
    "    direction = \"increases\" if row['Coefficient'] > 0 else \"decreases\"\n",
    "    print(f\"   - {row['Feature']}: {row['Coefficient']:.4f}\")\n",
    "    print(f\"     → 1 std increase {direction} price by ${abs(row['Coefficient']):.2f}k\")\n",
    "\n",
    "print(f\"\\n2. MODEL FIT QUALITY:\")\n",
    "print(f\"   - Training R² = {train_r2_sklearn:.4f} ({train_r2_sklearn*100:.1f}% variance explained)\")\n",
    "print(f\"   - Testing R²  = {test_r2_sklearn:.4f} ({test_r2_sklearn*100:.1f}% variance explained)\")\n",
    "\n",
    "print(f\"\\n3. PREDICTION ERROR:\")\n",
    "print(f\"   - Testing RMSE = ${np.sqrt(test_mse_sklearn):.2f}k\")\n",
    "print(f\"   - In dollars: ±${np.sqrt(test_mse_sklearn)*1000:.0f}\")\n",
    "\n",
    "print(f\"\\n4. GENERALIZATION:\")\n",
    "ratio = test_mse_sklearn / train_mse_sklearn\n",
    "print(f\"   - Test/Train MSE ratio = {ratio:.4f}\")\n",
    "if ratio < 1.1:\n",
    "    print(f\"   - Excellent generalization (minimal overfitting)\")\n",
    "elif ratio < 1.3:\n",
    "    print(f\"   - Good generalization (slight overfitting)\")\n",
    "else:\n",
    "    print(f\"   - Poor generalization (significant overfitting)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "efb0e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression_closed_form(X, y):\n",
    "    \"\"\"\n",
    "    Train linear regression using closed-form solution.\n",
    "    Formula: θ = (X^T X)^(-1) X^T y\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    X_with_intercept = np.column_stack([np.ones(N), X])\n",
    "    \n",
    "   \n",
    "    XTX = X_with_intercept.T @ X_with_intercept\n",
    "    XTy = X_with_intercept.T @ y\n",
    "    theta = np.linalg.solve(XTX, XTy)\n",
    "    \n",
    "    return theta\n",
    "\n",
    "\n",
    "def predict_linear_regression(X, theta):\n",
    "    \"\"\"Make predictions using learned parameters\"\"\"\n",
    "    N = X.shape[0]\n",
    "    X_with_intercept = np.column_stack([np.ones(N), X])\n",
    "    y_pred = X_with_intercept @ theta\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83713360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MY IMPLEMENTATION - COEFFICIENTS\n",
      "================================================================================\n",
      "\n",
      "Intercept (θ₀): 520.414834\n",
      "\n",
      "Feature Coefficients:\n",
      "--------------------------------------------------------------------------------\n",
      "  bedrooms            : -12.521962\n",
      "  bathrooms           :  18.527633\n",
      "  sqft_living         : 805.044513\n",
      "  sqft_lot            :  10.881868\n",
      "  floors              :   8.043721\n",
      "  waterfront          :  63.742900\n",
      "  view                :  48.200109\n",
      "  condition           :  12.964269\n",
      "  grade               :  92.231475\n",
      "  sqft_above          : -617.541764\n",
      "  sqft_basement       : -352.854033\n",
      "  yr_built            : -67.643117\n",
      "  yr_renovated        :  17.271380\n",
      "  lat                 :  78.375737\n",
      "  long                :  -1.035203\n",
      "  sqft_living15       :  45.577658\n",
      "  sqft_lot15          : -12.930091\n"
     ]
    }
   ],
   "source": [
    "theta_closed = train_linear_regression_closed_form(X_train_np, y_train_np)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MY IMPLEMENTATION - COEFFICIENTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nIntercept (θ₀): {theta_closed[0]:.6f}\\n\")\n",
    "print(\"Feature Coefficients:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i, feature in enumerate(X_train.columns):\n",
    "    print(f\"  {feature:20s}: {theta_closed[i+1]:10.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d3a40eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MY IMPLEMENTATION - METRICS\n",
      "================================================================================\n",
      "Training: MSE = 31486.167776, R² = 0.726533\n",
      "Testing:  MSE = 57628.154706, R² = 0.654356\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_train_pred_closed = predict_linear_regression(X_train_np, theta_closed)\n",
    "y_test_pred_closed = predict_linear_regression(X_test_np, theta_closed)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse_closed = mean_squared_error(y_train_np, y_train_pred_closed)\n",
    "train_r2_closed = r2_score(y_train_np, y_train_pred_closed)\n",
    "test_mse_closed = mean_squared_error(y_test_np, y_test_pred_closed)\n",
    "test_r2_closed = r2_score(y_test_np, y_test_pred_closed)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MY IMPLEMENTATION - METRICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Training: MSE = {train_mse_closed:.6f}, R² = {train_r2_closed:.6f}\")\n",
    "print(f\"Testing:  MSE = {test_mse_closed:.6f}, R² = {test_r2_closed:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9a25ded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARISON WITH SKLEARN\n",
      "================================================================================\n",
      "\n",
      "   Metric  My Implementation      sklearn   Difference\n",
      "Train MSE       31486.167776 31486.167776 7.275958e-12\n",
      " Train R²           0.726533     0.726533 0.000000e+00\n",
      " Test MSE       57628.154706 57628.154706 6.548362e-11\n",
      "  Test R²           0.654356     0.654356 3.330669e-16\n"
     ]
    }
   ],
   "source": [
    "# Comparison with sklearn\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Train MSE', 'Train R²', 'Test MSE', 'Test R²'],\n",
    "    'My Implementation': [train_mse_closed, train_r2_closed, test_mse_closed, test_r2_closed],\n",
    "    'sklearn': [train_mse_sklearn, train_r2_sklearn, test_mse_sklearn, test_r2_sklearn],\n",
    "    'Difference': [\n",
    "        abs(train_mse_closed - train_mse_sklearn),\n",
    "        abs(train_r2_closed - train_r2_sklearn),\n",
    "        abs(test_mse_closed - test_mse_sklearn),\n",
    "        abs(test_r2_closed - test_r2_sklearn)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON WITH SKLEARN\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b9a09428",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VALIDATION\n",
      "================================================================================\n",
      "Maximum difference: 6.55e-11\n",
      "Results are identical!\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "max_diff = comparison_df['Difference'].max()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Maximum difference: {max_diff:.2e}\")\n",
    "\n",
    "if max_diff < 1e-10:\n",
    "    print(\"Results are identical!\")\n",
    "elif max_diff < 1e-6:\n",
    "    print(\"Implementation is correct!\")\n",
    "else:\n",
    "    print(\"Check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca8bee",
   "metadata": {},
   "source": [
    "---\n",
    "# Problem 4: Polynomial Regression (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "74dc5dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial regression functions defined!\n"
     ]
    }
   ],
   "source": [
    "def create_polynomial_features(X, degree):\n",
    "    \"\"\"Create polynomial features [X, X², X³, ..., X^degree]\"\"\"\n",
    "    N = len(X)\n",
    "    X_poly = np.zeros((N, degree))\n",
    "    for p in range(1, degree + 1):\n",
    "        X_poly[:, p-1] = X ** p\n",
    "    return X_poly\n",
    "\n",
    "\n",
    "def train_polynomial_regression(X, y, degree):\n",
    "    \"\"\"Train polynomial regression using closed-form solution\"\"\"\n",
    "    X_poly = create_polynomial_features(X, degree)\n",
    "    N = X_poly.shape[0]\n",
    "    X_with_intercept = np.column_stack([np.ones(N), X_poly])\n",
    "    \n",
    "    XTX = X_with_intercept.T @ X_with_intercept\n",
    "    XTy = X_with_intercept.T @ y\n",
    "    theta = np.linalg.solve(XTX, XTy)\n",
    "    \n",
    "    return theta\n",
    "\n",
    "\n",
    "def predict_polynomial_regression(X, theta, degree):\n",
    "    \"\"\"Make predictions using polynomial regression\"\"\"\n",
    "    X_poly = create_polynomial_features(X, degree)\n",
    "    N = X_poly.shape[0]\n",
    "    X_with_intercept = np.column_stack([np.ones(N), X_poly])\n",
    "    y_pred = X_with_intercept @ theta\n",
    "    return y_pred\n",
    "\n",
    "print(\"Polynomial regression functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9de28470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using feature: sqft_living\n",
      "Training samples: 1000\n",
      "Testing samples: 1000\n"
     ]
    }
   ],
   "source": [
    "# Extract sqft_living feature\n",
    "X_train_sqft = train_data['sqft_living'].values\n",
    "y_train_poly = (train_data['price'] / 1000).values\n",
    "\n",
    "X_test_sqft = test_data['sqft_living'].values\n",
    "y_test_poly = (test_data['price'] / 1000).values\n",
    "\n",
    "print(f\"Using feature: sqft_living\")\n",
    "print(f\"Training samples: {len(X_train_sqft)}\")\n",
    "print(f\"Testing samples: {len(X_test_sqft)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3b45baee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1: Train R²=0.4967, Test R²=0.4687\n",
      "Degree 2: Train R²=0.5238, Test R²=0.5694\n",
      "Degree 3: Train R²=0.5329, Test R²=0.4012\n",
      "Degree 4: Train R²=0.5415, Test R²=-0.5053\n",
      "Degree 5: Train R²=0.5429, Test R²=-170.8815\n"
     ]
    }
   ],
   "source": [
    "degrees = [1, 2, 3, 4, 5]\n",
    "poly_results = []\n",
    "\n",
    "for p in degrees:\n",
    "    # Train\n",
    "    theta_poly = train_polynomial_regression(X_train_sqft, y_train_poly, p)\n",
    "    \n",
    "    # Predict\n",
    "    y_train_pred_poly = predict_polynomial_regression(X_train_sqft, theta_poly, p)\n",
    "    y_test_pred_poly = predict_polynomial_regression(X_test_sqft, theta_poly, p)\n",
    "    \n",
    "    # Metrics\n",
    "    train_mse = mean_squared_error(y_train_poly, y_train_pred_poly)\n",
    "    train_r2 = r2_score(y_train_poly, y_train_pred_poly)\n",
    "    test_mse = mean_squared_error(y_test_poly, y_test_pred_poly)\n",
    "    test_r2 = r2_score(y_test_poly, y_test_pred_poly)\n",
    "    \n",
    "    poly_results.append({\n",
    "        'Degree': p,\n",
    "        'Train MSE': train_mse,\n",
    "        'Train R²': train_r2,\n",
    "        'Test MSE': test_mse,\n",
    "        'Test R²': test_r2\n",
    "    })\n",
    "    \n",
    "    print(f\"Degree {p}: Train R²={train_r2:.4f}, Test R²={test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ebbb5995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "POLYNOMIAL REGRESSION SUMMARY\n",
      "================================================================================\n",
      "\n",
      " Degree    Train MSE  Train R²     Test MSE     Test R²\n",
      "      1 57947.526161  0.496709 8.857598e+04    0.468736\n",
      "      2 54822.665116  0.523849 7.179168e+04    0.569406\n",
      "      3 53785.194716  0.532860 9.983348e+04    0.401216\n",
      "      4 52795.774758  0.541453 2.509793e+05   -0.505331\n",
      "      5 52626.111955  0.542927 2.865728e+07 -170.881541\n"
     ]
    }
   ],
   "source": [
    "poly_results_df = pd.DataFrame(poly_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POLYNOMIAL REGRESSION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + poly_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134eb21",
   "metadata": {},
   "source": [
    "# Problem 5: Gradient Descent (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27af66",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9a7770a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, theta):\n",
    "    \"\"\"Compute MSE cost function\"\"\"\n",
    "    N = len(y)\n",
    "    X_with_intercept = np.column_stack([np.ones(N), X])\n",
    "    predictions = X_with_intercept @ theta\n",
    "    cost = (1 / N) * np.sum((predictions - y) ** 2)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def compute_gradient(X, y, theta):\n",
    "    \"\"\"Compute gradient of MSE cost function\"\"\"\n",
    "    N = len(y)\n",
    "    X_with_intercept = np.column_stack([np.ones(N), X])\n",
    "    predictions = X_with_intercept @ theta\n",
    "    gradient = (2 / N) * X_with_intercept.T @ (predictions - y)\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def gradient_descent(X, y, alpha, num_iterations):\n",
    "    \"\"\"Perform gradient descent optimization\"\"\"\n",
    "    N, d = X.shape\n",
    "    theta = np.zeros(d + 1)\n",
    "    cost_history = []\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        gradient = compute_gradient(X, y, theta)\n",
    "        theta = theta - alpha * gradient\n",
    "        cost = compute_cost(X, y, theta)\n",
    "        cost_history.append(cost)\n",
    "    \n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b52413a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.1, 0.5]\n",
    "iteration_counts = [10, 50, 100]\n",
    "gd_results = []\n",
    "\n",
    "for alpha in learning_rates:\n",
    "    for num_iter in iteration_counts:\n",
    "        # Train\n",
    "        theta_gd, _ = gradient_descent(X_train_np, y_train_np, alpha, num_iter)\n",
    "        \n",
    "        # Predict\n",
    "        X_train_int = np.column_stack([np.ones(len(X_train_np)), X_train_np])\n",
    "        X_test_int = np.column_stack([np.ones(len(X_test_np)), X_test_np])\n",
    "        \n",
    "        y_train_pred_gd = X_train_int @ theta_gd\n",
    "        y_test_pred_gd = X_test_int @ theta_gd\n",
    "        \n",
    "        # Metrics\n",
    "        train_mse_gd = mean_squared_error(y_train_np, y_train_pred_gd)\n",
    "        train_r2_gd = r2_score(y_train_np, y_train_pred_gd)\n",
    "        test_mse_gd = mean_squared_error(y_test_np, y_test_pred_gd)\n",
    "        test_r2_gd = r2_score(y_test_np, y_test_pred_gd)\n",
    "        \n",
    "        gd_results.append({\n",
    "            'Learning Rate': alpha,\n",
    "            'Iterations': num_iter,\n",
    "            'Train MSE': train_mse_gd,\n",
    "            'Train R²': train_r2_gd,\n",
    "            'Test MSE': test_mse_gd,\n",
    "            'Test R²': test_r2_gd\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a8b49295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GRADIENT DESCENT SUMMARY\n",
      "================================================================================\n",
      "\n",
      " Learning Rate  Iterations     Train MSE       Train R²      Test MSE        Test R²\n",
      "          0.01          10  2.357278e+05  -1.047365e+00  2.805687e+05  -6.828036e-01\n",
      "          0.01          50  6.972050e+04   3.944571e-01  9.704954e+04   4.179133e-01\n",
      "          0.01         100  3.682035e+04   6.802045e-01  6.333304e+04   6.201392e-01\n",
      "          0.10          10  3.510510e+04   6.951019e-01  6.163043e+04   6.303511e-01\n",
      "          0.10          50  3.149726e+04   7.264371e-01  5.772248e+04   6.537904e-01\n",
      "          0.10         100  3.148643e+04   7.265311e-01  5.763896e+04   6.542913e-01\n",
      "          0.50          10  1.456064e+17  -1.264635e+12  1.626068e+17  -9.752880e+11\n",
      "          0.50          50  1.259542e+67  -1.093949e+62  1.406601e+67  -8.436553e+61\n",
      "          0.50         100 3.322792e+129 -2.885942e+124 3.710745e+129 -2.225642e+124\n"
     ]
    }
   ],
   "source": [
    "gd_results_df = pd.DataFrame(gd_results)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GRADIENT DESCENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + gd_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3fb7972c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARISON WITH CLOSED-FORM SOLUTION\n",
      "================================================================================\n",
      "\n",
      "Closed-form:     Train MSE = 31486.167776\n",
      "Best GD (α=0.1): Train MSE = 31486.431792\n",
      "Difference:      0.26401611\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARISON WITH CLOSED-FORM SOLUTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_gd = gd_results_df[(gd_results_df['Learning Rate'] == 0.1) & \n",
    "                        (gd_results_df['Iterations'] == 100)].iloc[0]\n",
    "\n",
    "print(f\"\\nClosed-form:     Train MSE = {train_mse_closed:.6f}\")\n",
    "print(f\"Best GD (α=0.1): Train MSE = {best_gd['Train MSE']:.6f}\")\n",
    "print(f\"Difference:      {abs(best_gd['Train MSE'] - train_mse_closed):.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8931c5ed",
   "metadata": {},
   "source": [
    "---\n",
    "# Problem 6: Ridge Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25092c",
   "metadata": {},
   "source": [
    "## Part 2: Implementation with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6d866bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ridge_gradient(X, y, theta, lambda_param):\n",
    "    \"\"\"Compute gradient for ridge regression\"\"\"\n",
    "    N = len(y)\n",
    "    X_with_intercept = np.column_stack([np.ones(N), X])\n",
    "    predictions = X_with_intercept @ theta\n",
    "    \n",
    "   \n",
    "    base_gradient = (2 / N) * X_with_intercept.T @ (predictions - y)\n",
    "    \n",
    "\n",
    "    regularization = np.zeros_like(theta)\n",
    "    regularization[1:] = 2 * lambda_param * theta[1:]\n",
    "    \n",
    "    return base_gradient + regularization\n",
    "\n",
    "\n",
    "def ridge_gradient_descent(X, y, lambda_param, alpha=0.01, num_iterations=1000):\n",
    "    \"\"\"Perform gradient descent for ridge regression\"\"\"\n",
    "    N, d = X.shape\n",
    "    theta = np.zeros(d + 1)\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        gradient = compute_ridge_gradient(X, y, theta, lambda_param)\n",
    "        theta = theta - alpha * gradient\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493c858",
   "metadata": {},
   "source": [
    "## Part 3: Simulated Data Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1ed3ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated data: Y = 1 + 2X + ε\n",
      "N = 1000, ε ~ N(0, 2)\n"
     ]
    }
   ],
   "source": [
    "N_sim = 1000\n",
    "X_sim = np.random.uniform(-2, 2, N_sim).reshape(-1, 1)\n",
    "noise = np.random.normal(0, np.sqrt(2), N_sim)\n",
    "y_sim = 1 + 2 * X_sim.flatten() + noise\n",
    "\n",
    "print(\"Simulated data: Y = 1 + 2X + ε\")\n",
    "print(f\"N = {N_sim}, ε ~ N(0, 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "92b2889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ=    0: Slope=1.945275, MSE=1.949936\n",
      "λ=    1: Slope=1.943850, MSE=1.949939\n",
      "λ=   10: Slope=1.931119, MSE=1.950209\n",
      "λ=  100: Slope=1.812414, MSE=1.974016\n",
      "λ= 1000: Slope=1.122450, MSE=2.873516\n",
      "λ=10000: Slope=0.233509, MSE=5.947067\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lambda_values = [0, 1, 10, 100, 1000, 10000]\n",
    "ridge_results = []\n",
    "\n",
    "for lam in lambda_values:\n",
    "    N = len(X_sim)\n",
    "    X_with_intercept = np.column_stack([np.ones(N), X_sim])\n",
    "    \n",
    "    \n",
    "    L = np.eye(X_with_intercept.shape[1])\n",
    "    L[0, 0] = 0\n",
    "\n",
    "   \n",
    "    XTX = X_with_intercept.T @ X_with_intercept\n",
    "    XTy = X_with_intercept.T @ y_sim\n",
    "    theta_ridge = np.linalg.solve(XTX + lam * L, XTy)\n",
    "    y_pred_ridge = X_with_intercept @ theta_ridge\n",
    "    mse_ridge = mean_squared_error(y_sim, y_pred_ridge)\n",
    "    r2_ridge = r2_score(y_sim, y_pred_ridge)\n",
    "    \n",
    "    ridge_results.append({\n",
    "        'λ': lam,\n",
    "        'Intercept': theta_ridge[0],\n",
    "        'Slope': theta_ridge[1],\n",
    "        'MSE': mse_ridge,\n",
    "        'R²': r2_ridge\n",
    "    })\n",
    "    \n",
    "    print(f\"λ={lam:5d}: Slope={theta_ridge[1]:.6f}, MSE={mse_ridge:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "46924bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RIDGE REGRESSION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "    λ  Intercept    Slope      MSE       R²\n",
      "    0   1.001987 1.981148 2.099933 0.713418\n",
      "    1   1.001944 1.979662 2.099936 0.713418\n",
      "   10   1.001567 1.966384 2.100223 0.713379\n",
      "  100   0.998056 1.842789 2.125429 0.709939\n",
      " 1000   0.977850 1.131558 3.061293 0.582220\n",
      "10000   0.952317 0.232853 6.170893 0.157847\n"
     ]
    }
   ],
   "source": [
    "# Results table\n",
    "ridge_results_df = pd.DataFrame(ridge_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RIDGE REGRESSION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + ridge_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8c588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
